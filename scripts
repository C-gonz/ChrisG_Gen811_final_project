5-8-20 (db_and_blastp.slurm script for BLASTp pipeline.)

#!/bin/bash

## Note - Slurm script comments require two hash symbols (##).  A single
## hash symbol immediately followed by SBATCH indicates an SBATCH
## directive.  "##SBATCH" indicates the SBATCH command is commented
## out and is inactive.

#SBATCH --exclude=node117,node118

## NTasks is not thread count, be sure to leave it set at 1
#SBATCH --ntasks=1

## If your program will be using less than 24 threads, or you
## require more than 24 threads, set cpus-per-task to the 
## desired threadcount.  Leave this commented out for the
## default 24 threads.
##SBATCH --cpus-per-task=2

## You will need to specify a minimum amount of memory in the
## following situaitons:
##   1. If you require more than 128GB of RAM, specify either:
##      a. "--mem=512000" for at least 512GB of RAM (6 possible nodes)
##      b. "--mem=1000000" for at least 1TB of RAM (2 possible nodes)
##   2. If you are running a job with less than 24 threads, you will
##      normally be given your thread count times 5.3GB in RAM.  So
##      a single thread would be given about 5GB of RAM.  If you
##      require more, please specify it as a "--mem=XXXX" option,
##      but avoid using all available RAM so others may share the node.
##SBATCH --mem=512000

## Normally jobs will restart automatically if the cluster experiences
## an unforeseen issue.  This may not be desired if you want to retain
## the work that's been performed by your script so far.   
## --no-requeue

## Normal Slurm options
## SBATCH -p shared
#SBATCH --job-name="Blastp_T1Rs"
#SBATCH --output=T1Rs_blastp.output

## Load the appropriate modules first.  Linuxbrew/colsa contains most
## programs, though some are contained within the anaconda/colsa
## module.  Refer to http://premise.sr.unh.edu for more info.
module purge
module load linuxbrew/colsa
##module load anaconda/colsa
##source activate <PROGRAM HERE>


## Instruct your program to make use of the number of desired threads.
## As your job will be allocated an entire node, this should normally
## be 24.

## For loop to run through each gzip fasta file, make a BLAST database from it, then blast a set query against each database. 
for item in ./*.gz
do
    ## make the blast database from the mus_musculus genome-based protein dataset 
    gzip -dc $item | makeblastdb -out ${item%.*}_db -dbtype prot -title $item

    ## blastp the 3 mus_musculus T1Rs against each species' BLAST database  
    blastp -db ${item%.*}_db -query mus_musculus_T1Rs.fas -evalue 1e-05 -num_threads 24 -out ${item%.*}.out -outfmt '6 qseqid qlen length pident gaps evalue stitle'

    ## Identify the total number of unique query seqs with significant hits, and those with selected key
    ## terms in their title. Append all counts to each blast output file, and use grep to ID & append GPCR seq titles
    ## & their e-values to one file.
    unique_seqs=$(cut -f 7 ${item%.*}.out | sort | uniq | wc -l)

    taste_seqs=$(cut -f 7 ${item%.}.out | sort | uniq | grep -i "taste" | wc -l)
    (cut -f 6,7 ${item%.*}.out | sort | uniq | grep -i "taste") >> unique_GPCR_seqs.txt

    metabotropic_seqs=$(cut -f 7 ${item%.}.out | sort | uniq | grep -i "metabotropic" | wc -l)
    (cut -f 6,7 ${item%.*}.out | sort | uniq | grep -i "metabotropic") >> unique_GPCR_seqs.txt

    vomeronasal_seqs=$(cut -f 7 ${item%.}.out | sort | uniq | grep -i "vomeronasal" | wc -l)
    (cut -f 6,7 ${item%.*}.out | sort | uniq | grep -i "vomeronasal") >> unique_GPCR_seqs.txt

    ## echo statements to record the significant hit seqs in the blast output file and the T1Rs_blastp.output file.
    echo There are $unique_seqs unique query sequences with significant hits $metabotropic_seqs contain the term metabotropic $taste_seqs contain taste and $vomeronasal_seqs contain vomeronasal >> ${item%.*}.out
    echo In ${item%.}.out there are $unique_seqs unique query sequences with significant hits $metabotropic_seqs contain the term metabotropic $taste_seqs contain taste and $vomeronasal_seqs contain vomeronasal
    echo Database creation and BLASTp query for $item is complete
done



#4-26-20

#command used to obtain puiblic reference genomes for my TR analyses
wget <ftp link for genome>

#ftp links used to obtain 5 reference genomes

#Reference purple sea urchin genome: 
ftp://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/002/235/GCF_000002235.5_Spur_5.0/GCF_000002235.5_Spur_5.0_genomic.fna.gz

#Reference Mus Musculus genome:
https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/635/GCF_000001635.26_GRCm38.p6/GCF_000001635.26_GRCm38.p6_genomic.fna.gz

#Reference Zebrafish genome:
https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/002/035/GCF_000002035.6_GRCz11/GCF_000002035.6_GRCz11_genomic.fna.gz

#Reference Drosophila genome:
https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/001/215/GCF_000001215.4_Release_6_plus_ISO1_MT/GCF_000001215.4_Release_6_plus_ISO1_MT_genomic.fna.gz

#Reference Cnidarian (Hydra vulgaris) genome:
https://ftp.ncbi.nlm.nih.gov/genomes/all/GCF/000/004/095/GCF_000004095.1_Hydra_RP_1.0/GCF_000004095.1_Hydra_RP_1.0_genomic.fna.gz


